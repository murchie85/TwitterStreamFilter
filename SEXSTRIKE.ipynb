{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MURCHIE85 TWITTER ANALYTICS (TOPIC = #SEXSTRIKE)\n",
    "\n",
    "  \n",
    "    \n",
    "\n",
    "![image](https://i.ytimg.com/vi/VCJfT9CTuds/maxresdefault.jpg)\n",
    "\n",
    "\n",
    "This repo is for pulling metrics on a given keyword (best use keywords that are hashtagged) and performs a series of reporting and analysis.\n",
    "\n",
    "\n",
    "\n",
    "## AUTOMATED RESEARCH SUMMARY\n",
    "\n",
    "\n",
    "The majority of tweeters on this topic describe themselves in their Bio with **'God'** , **'Trump'** and **'#MAGA'**\n",
    "The top most popular words tweeted are :\n",
    "\n",
    "- **Alabama**\n",
    "- **#NoUterusNoOpinion**\n",
    "- **#Alabama**\n",
    "- **AlabamaAbortionBan**\n",
    "- **ProChoice**\n",
    "- **#AlabamaSenate**\n",
    "- **abortion**\n",
    "- **prayers**\n",
    "- **raped**\n",
    "- **#ProChoice**\n",
    "\n",
    "\n",
    "VIEWS WERE MOSTLY : **SUBJECTIVE**  (50%) & **NEGATIVELY-SUBJECTIVE** (30%)\n",
    "\n",
    "\n",
    "\n",
    "## OVERVIEW\n",
    "\n",
    "**SKIP TO BOTTOM FOR FULL RESULTS & GRAPH BREAKDOWN **\n",
    "\n",
    "- Pulls live tweets from all over twitter \n",
    "- Imports Tweepy Library \n",
    "- Consumes Twitter API \n",
    "- Desgined to be keyword driven\n",
    "- All metrics can be captured\n",
    "- No limit on Runtime (best to terminate when you want)\n",
    "\n",
    "## Limitations & info\n",
    "1. LOCATION filter is tricky\n",
    "2. Streaming connects to the “public streams” (all public data) \n",
    "3. This is data provided by the Twitter API which accesses their database, the maintenence of DB and thus data quality is managed by Twitter\n",
    "\n",
    "Example of parameter setting done in stream filter \n",
    "\n",
    "```\n",
    "stream.filter(follow=[\"2211149702\"])\n",
    "```\n",
    "\n",
    "\n",
    "### AUTHOR : ADAM MCMURCHIE \n",
    "\n",
    "![image](https://s3.amazonaws.com/re-work-production/avatars/1104/original.png?1485507466)\n",
    "\n",
    "Github [here](https://github.com/murchie85)  \n",
    "\n",
    "Mysite [here](https://murchie85.github.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTHENTICATION\n",
    "\n",
    "You will need to change f variable to point to your credentials file, I save mines in a text file and split the comma. Not uploaded to this repo obviously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "f = open(\"../donotgit/access.txt\", \"r\")\n",
    "keys = f.read()\n",
    "f.close()\n",
    "keys  = keys.split(',')\n",
    "#print(\"Access Keys are : \" + str(keys))\n",
    "ACCESS_TOKEN = keys[0]\n",
    "ACCESS_SECRET = keys[1]\n",
    "\n",
    "\n",
    "f = open(\"../donotgit/consumer.txt\", \"r\")\n",
    "keys = f.read()\n",
    "keys  = keys.split(',')\n",
    "#print(\"Consumer Keys are : \" + str(keys))\n",
    "CONSUMER_KEY = keys[0]\n",
    "CONSUMER_SECRET = keys[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PULLING DOWN THE DATA \n",
    "\n",
    "This is where the magic happens, api authentication is set up, tweepy library is imported for the work and a class allow us to pull live data. This is appended to array for processing later. \n",
    "\n",
    "If you want to change the parameters, edit the following line:  \n",
    "\n",
    "```\n",
    "stream.filter(track=[\"SexStrike\"],languages=[\"en\"])\n",
    "```\n",
    "\n",
    "*NOTE* -   this will just keep running until you force terminate, i haven't added in a terminate loop yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "import sys\n",
    "# Import the necessary package to process data in JSON format\n",
    "try:\n",
    "    import json\n",
    "except ImportError:\n",
    "    import simplejson as json\n",
    "\n",
    "# Import the tweepy library\n",
    "import tweepy\n",
    "\n",
    "# Variables that contains the user credentials to access Twitter API \n",
    "# Captured earlier \n",
    "\n",
    "# Setup tweepy to authenticate with Twitter credentials:\n",
    "\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "# Create the api to connect to twitter with your creadentials\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, compression=True)\n",
    "\n",
    "status_array = []\n",
    "\n",
    "\n",
    "max_count = 1000\n",
    "\n",
    "f = IntProgress(min=0, max=max_count) # instantiate the bar\n",
    "display(f) # display the bar\n",
    "\n",
    "\n",
    "\n",
    "class StreamListener(tweepy.StreamListener):\n",
    "    tweet_number=0   # class variable\n",
    "    \n",
    "\n",
    "\n",
    "    def on_status(self, status):\n",
    "        self.max_tweets=max_count # max number of tweets\n",
    "        self.tweet_number+=1   \n",
    "        f.value += 1 # signal to increment the progress bar\n",
    "        time.sleep(.1)\n",
    "        status_array.append(status._json)\n",
    "\n",
    "        if self.tweet_number>=self.max_tweets:\n",
    "            sys.exit('PROCESSING COMPLETE : '+str(self.max_tweets)+' tweets processed.')\n",
    "\n",
    "        \n",
    "    def on_error(self, status_code):\n",
    "        if status_code == 420:\n",
    "            return False\n",
    "\n",
    "stream_listener = StreamListener()\n",
    "stream = tweepy.Stream(auth=api.auth, listener=stream_listener)\n",
    "\n",
    "print('Pulling down data.....')\n",
    "stream.filter(track=[\"SexStrike\"],languages=[\"en\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRINT AND SAVE DATA\n",
    "\n",
    "This section allows me to pull the recently mined data into a file in raw format incase i need it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currentDT = datetime.datetime.now()\n",
    "filename = \"data/streamout-\" + str(currentDT) + \".txt\"\n",
    "\n",
    "print(filename)\n",
    "\n",
    "with open(filename, 'w') as f:\n",
    "    for item in status_array:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STREAM METADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of records')\n",
    "print(len(status_array))\n",
    "print('')\n",
    "print('The data keys are : ')\n",
    "print(status_array[0].keys())\n",
    "print('')\n",
    "print('An example element looks like: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPORT GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# WRITE OUT FULL REPORT\n",
    "reportfile = \"reports/printout-\"+ str(currentDT) + \".txt\"\n",
    "descriptionfile = \"data/description/printout-\"+ str(currentDT) + \".txt\"\n",
    "tweetfile = \"data/tweet/printout-\"+ str(currentDT) + \".txt\"\n",
    "\n",
    "REPORTCOUNT = 0\n",
    "with open(reportfile, 'w') as f:\n",
    "    for y in range(0, len(status_array)):\n",
    "        REPORTCOUNT = REPORTCOUNT + 1\n",
    "        f.write('************************************************************\\n')\n",
    "        f.write(status_array[y]['text'])\n",
    "        f.write('------------------------------\\n')\n",
    "        f.write(status_array[y]['created_at'])\n",
    "        f.write('------------------------------\\n')\n",
    "        f.write(status_array[y]['user']['name'])\n",
    "        f.write('------------------------------\\n')\n",
    "        f.write(str(status_array[y]['user']['location']))\n",
    "        f.write('------------------------------\\n')\n",
    "        f.write(str(status_array[y]['user']['description']))\n",
    "        f.write('--------------REPLY COUNT----------------\\n|')\n",
    "        f.write(str(status_array[y]['reply_count']))\n",
    "        f.write('--------------RETWEET COUNT----------------\\n')\n",
    "        f.write(str(status_array[y]['retweet_count']))\n",
    "        f.write('--------------RETWEETED?----------------\\n')\n",
    "        f.write(str(status_array[y]['retweeted']))\n",
    "        f.write('--------------RETWEET COUNT----------------\\n')\n",
    "        f.write(str(status_array[y]['retweet_count']))\n",
    "        f.write('--------------FAVOURITED----------------\\n')\n",
    "        f.write(str(status_array[y]['favorited']))\n",
    "        f.write('--------------FAVOURITE COUNT----------------\\n')\n",
    "        f.write(str(status_array[y]['favorite_count']))\n",
    "        f.write('\\n')\n",
    "        f.write('\\n')\n",
    "    f.write('number of records are : ')\n",
    "    f.write(str(REPORTCOUNT))\n",
    "        \n",
    "f.close()\n",
    "    \n",
    "    \n",
    "# WRITE OUT ONLY DESCRIPTION\n",
    "    \n",
    "REPORTCOUNT = 0\n",
    "with open(descriptionfile, 'w') as f:\n",
    "    for y in range(0, len(status_array)):\n",
    "        REPORTCOUNT = REPORTCOUNT + 1\n",
    "        f.write('************************************************************\\n')\n",
    "        f.write(str(status_array[y]['user']['description']))\n",
    "        f.write('\\n')\n",
    "    f.write('number of records are : ')\n",
    "    f.write(str(REPORTCOUNT))\n",
    "        \n",
    "f.close()\n",
    "    \n",
    "\n",
    "# WRITE OUT ONLY TWEET\n",
    "    \n",
    "REPORTCOUNT = 0\n",
    "with open(tweetfile, 'w') as f:\n",
    "    for y in range(0, len(status_array)):\n",
    "        REPORTCOUNT = REPORTCOUNT + 1\n",
    "        f.write('************************************************************\\n')\n",
    "        f.write(status_array[y]['text'])\n",
    "        f.write('\\n')\n",
    "    f.write('number of records are : ')\n",
    "    f.write(str(REPORTCOUNT))\n",
    "        \n",
    "f.close()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "print('=========================SAMPLE OUTPUT================================')\n",
    "print('************************************************************')\n",
    "print(status_array[0]['text'])\n",
    "print('------------------------------')\n",
    "print(status_array[0]['created_at'])\n",
    "print('------------------------------')\n",
    "print(status_array[0]['user']['name'])\n",
    "print('------------------------------')\n",
    "print(status_array[0]['user']['location'])\n",
    "print('------------------------------')\n",
    "print(status_array[0]['user']['description'])\n",
    "print('--------------REPLY COUNT----------------')\n",
    "print(status_array[0]['reply_count'])\n",
    "print('--------------RETWEET COUNT----------------')\n",
    "print(status_array[0]['retweet_count'])\n",
    "print('--------------RETWEETED?----------------') \n",
    "print(status_array[0]['retweeted'])\n",
    "print('--------------RETWEET COUNT----------------')\n",
    "print(status_array[0]['retweet_count'])\n",
    "print('--------------FAVOURITED----------------')\n",
    "print(status_array[0]['favorited'])\n",
    "print('--------------FAVOURITE COUNT----------------')\n",
    "print(status_array[0]['favorite_count'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## USER DESCRIPTION NUMERICAL ANALYSIS\n",
    "\n",
    "Change the below values to see how they rank in tweet frequency \n",
    "\n",
    "```\n",
    "WORDONE='#MAGA'\n",
    "WORDTWO='me'\n",
    "WORDTHREE='life'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "WORDONE='#MAGA'\n",
    "WORDTWO='me'\n",
    "WORDTHREE='life'\n",
    "\n",
    "WORDONE_COUNT = 0\n",
    "WORDTWO_COUNT = 0 \n",
    "WORDTHREE_COUNT = 0 \n",
    "\n",
    "linecount = 0\n",
    "APPENDED_DESCRIPTION = \"\"\n",
    "\n",
    "\n",
    "\n",
    "for x in range(0, len(status_array)):\n",
    "    linecount = linecount + 1\n",
    "    description = status_array[x]['user']['description']\n",
    "    APPENDED_DESCRIPTION = APPENDED_DESCRIPTION + str(description)\n",
    "    \n",
    "    \n",
    "    if str(description).count(str(WORDONE)) >= 1:\n",
    "        WORDONE_COUNT = WORDONE_COUNT + 1\n",
    "\n",
    "    if str(description).count(str(WORDTWO)) >= 1:\n",
    "        WORDTWO_COUNT = WORDTWO_COUNT + 1\n",
    "\n",
    "    if str(description).count(str(WORDTHREE)) >= 1:\n",
    "        WORDTHREE_COUNT = WORDTHREE_COUNT + 1\n",
    "        \n",
    "print('Total count of words - ' + str(WORDONE) + ' :' + str(WORDONE_COUNT))\n",
    "print('Total count of words - ' + str(WORDTWO) + ' :' + str(WORDTWO_COUNT))\n",
    "print('Total count of words - ' + str(WORDTHREE) + ' :' + str(WORDTHREE_COUNT))\n",
    "print('Total Number of Records: ' + str(linecount))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "DISC = APPENDED_DESCRIPTION.split()\n",
    "x = Counter(DISC)\n",
    "del x['⠀'],x['what'],x['their'],x['or'],x['love'],x['Love'],x['things'],x[\"don't\"], x[\"and\"], x[\"the\"], x[\"of\"],x[\"to\"], x[\"a\"], x[\"I\"], x[\"&\"], x[\"in\"], x[\"for\"], x[\"my\"], x[\"is\"], x[\"the\"], x[\"are\"], x[\"you\"], x[\"on\"]\n",
    "del x[\"with\"], x['We'],x['we'],x[\"not\"], x[\"but\"], x[\"be\"],x['can'], x[\"The\"],x['out'], x[\"No\"], x[\"who\"], x[\"|\"], x[\"about\"], x[\"that\"], x[\"your\"], x[\"•\"], x['from'], x['-'], x['it'], x['am'], x[','], x['like'],x['just']\n",
    "del x['It'],x[\"I'm\"],x[\"I’m\"], x['A'],x['our'],x['/'],x['-'],x['this'],x['have'],x['by'],x['an'],x['going'],x['they'],x['having'],x['all'],x['at'],x['good'],x['do'],x['love'],x['as'],x['My'],x['i'],x['always'],x['me'],x['get'],x['will'],x['so'],x['can',x['⠀']]\n",
    "\n",
    "\n",
    "      \n",
    "            \n",
    "top_desc = OrderedDict(x.most_common(20))\n",
    "print(top_desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "D = top_desc\n",
    "\n",
    "plt.bar(range(len(D)), list(D.values()), align='center')\n",
    "plt.xticks(range(len(D)), list(D.keys()), rotation='vertical')\n",
    "plt.title(\"Tweeters Bio - Most popular Terms\", fontsize=30)\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TWEET NUMERICAL ANALYSIS\n",
    "\n",
    "Change the below values to see how they rank in tweet frequency \n",
    "\n",
    "```\n",
    "WORDONE='Alabama'\n",
    "WORDTWO='abortion'\n",
    "WORDTHREE='life'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "WORDONE='Alabama'\n",
    "WORDTWO='abortion'\n",
    "WORDTHREE='life'\n",
    "\n",
    "WORDONE_COUNT = 0\n",
    "WORDTWO_COUNT = 0 \n",
    "WORDTHREE_COUNT = 0 \n",
    "linecount = 0\n",
    "APPENDED_TEXT = \"\"\n",
    "\n",
    "\n",
    "for x in range(0, len(status_array)):\n",
    "    linecount = linecount + 1\n",
    "    text = status_array[x]['text']\n",
    "    APPENDED_TEXT = APPENDED_TEXT + str(text)\n",
    "    \n",
    "    \n",
    "    if str(text).count(str(WORDONE)) >= 1:\n",
    "        WORDONE_COUNT = WORDONE_COUNT + 1\n",
    "\n",
    "    if str(text).count(str(WORDTWO)) >= 1:\n",
    "        WORDTWO_COUNT = WORDTWO_COUNT + 1\n",
    "\n",
    "    if str(text).count(str(WORDTHREE)) >= 1:\n",
    "        WORDTHREE_COUNT = WORDTHREE_COUNT + 1\n",
    "        \n",
    "print('Total count of words - ' + str(WORDONE) + ' :' + str(WORDONE_COUNT))\n",
    "print('Total count of words - ' + str(WORDTWO) + ' :' + str(WORDTWO_COUNT))\n",
    "print('Total count of words - ' + str(WORDTHREE) + ' :' + str(WORDTHREE_COUNT))\n",
    "print('Total Number of Records: ' + str(linecount))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(APPENDED_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "DISC = APPENDED_TEXT.split()\n",
    "x = Counter(DISC)\n",
    "del x['⠀'],x['what'],x['their'],x['or'],x['love'],x['Love'],x['things'],x[\"don't\"], x[\"and\"], x[\"the\"], x[\"of\"],x[\"to\"], x[\"a\"], x[\"I\"], x[\"&\"], x[\"in\"], x[\"for\"], x[\"my\"], x[\"is\"], x[\"the\"], x[\"are\"], x[\"you\"], x[\"on\"]\n",
    "del x[\"with\"], x['We'],x['we'],x[\"not\"], x[\"but\"], x[\"be\"],x['can'], x[\"The\"],x['out'], x[\"No\"], x[\"who\"], x[\"|\"], x[\"about\"], x[\"that\"], x[\"your\"], x[\"•\"], x['from'], x['-'], x['it'], x['am'], x[','], x['like'],x['just']\n",
    "del x['It'],x[\"I'm\"],x[\"I’m\"], x['A'],x['our'],x['/'],x['-'],x['this'],x['have'],x['by'],x['an'],x['going'],x['they'],x['having'],x['all'],x['at'],x['good'],x['do'],x['love'],x['as'],x['My'],x['i'],x['always'],x['me'],x['get'],x['will'],x['so'],x['can',x['⠀']]\n",
    "\n",
    "    \n",
    "\n",
    "top_tweets = OrderedDict(x.most_common(20))\n",
    "print(top_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "D = top_tweets\n",
    "\n",
    "plt.bar(range(len(D)), list(D.values()), align='center')\n",
    "plt.xticks(range(len(D)), list(D.keys()), rotation='vertical')\n",
    "plt.title(\"Most Frequent Words Tweeted\", fontsize=30)\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SENTIMENT ANALYSIS \n",
    "\n",
    "The sentiment property returns a named tuple of the form Sentiment (polarity, subjectivity). The polarity score is a float within the range [-1.0, 1.0]. The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective.\n",
    "\n",
    "# Now the Theory\n",
    "Thanks to Siraj Raval and freecode camp for the sample here\n",
    "\n",
    "TextBlob\n",
    "TextBlob is a Python (2 and 3) library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.\n",
    "\n",
    "A textblob can be created in the following way (example, and not part of the original code):\n",
    "\n",
    "example = TextBlob(\"Python is a high-level, general-purpose programming language.\")\n",
    "And tokenization can be performed by the following methods:\n",
    "words: returns the words of text\n",
    "\n",
    "usage:\n",
    "\n",
    "example.words\n",
    "sentences: returns the sentences of text\n",
    "\n",
    "usage:\n",
    "\n",
    "example.sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweepy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-848a34259061>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOAuthHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONSUMER_KEY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONSUMER_SECRET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_access_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mACCESS_TOKEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mACCESS_SECRET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tweepy' is not defined"
     ]
    }
   ],
   "source": [
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "public_tweets = api.search('#SexStrike')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_tweet=0\n",
    "subjective_tweet=0\n",
    "negitively_subjective=0\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.text)\n",
    "    analysis = TextBlob(tweet.text)\n",
    "    print(analysis.sentiment)\n",
    "    if analysis.sentiment[0]>0:\n",
    "       subjective_tweet = subjective_tweet + 1\n",
    "       print('Subjective')\n",
    "    elif analysis.sentiment[0]<0:\n",
    "       negitively_subjective = negitively_subjective  + 1\n",
    "       print('Negatively subjective')\n",
    "    else:\n",
    "       objective_tweet = objective_tweet + 1\n",
    "       print('objective')\n",
    "    print('\\n')\n",
    "    \n",
    "print('objective_tweets : '+str(objective_tweet))\n",
    "print('subjective_tweets : '+str(subjective_tweet))\n",
    "print('negitively_subjective tweets: '+str(negitively_subjective))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
